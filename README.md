# DL-PhawIA: Detecci√≥n de Retinopat√≠a Diab√©tica

## üìã Descripci√≥n

Este proyecto implementa un sistema de clasificaci√≥n autom√°tica para la detecci√≥n de retinopat√≠a diab√©tica utilizando t√©cnicas de Deep Learning. Se comparan tres arquitecturas de redes neuronales convolucionales (CNN) para evaluar su efectividad en la clasificaci√≥n de im√°genes de retina en diferentes grados de severidad.

## üîó Repositorio del Proyecto

**Enlace p√∫blico**: https://github.com/haroldeustaquio/Proyecto_EustaquioHarold_Clasificacion

El c√≥digo completo, notebooks, modelos entrenados y resultados est√°n disponibles en el repositorio de GitHub.

## üóÇÔ∏è Ruta Elegida y Dataset

### Dataset Utilizado
- **Fuente**: APTOS 2019 Blindness Detection (Kaggle)
- **Link**: https://www.kaggle.com/competitions/aptos2019-blindness-detection
- **Tipo**: Im√°genes de retina del concurso APTOS 2019 ‚Äì Blindness Detection
- **Clases**: Clasificaci√≥n en cinco niveles de severidad (0: No DR, 1: Mild, 2: Moderate, 3: Severe, 4: Proliferative DR)
- **Reagrupaci√≥n**: Las clases se reagrupan en 3 categor√≠as finales:
  - Clase 0: Sin retinopat√≠a (original: 0)
  - Clase 1: Retinopat√≠a leve/moderada (original: 1, 2)
  - Clase 2: Retinopat√≠a severa/proliferativa (original: 3, 4)
- **Formato**: Formato JPG
- **Preprocesamiento**: Recorte centrado, CLAHE, filtro bilateral
- **Divisi√≥n**: Divisi√≥n estratificada: 60% entrenamiento, 20% validaci√≥n, 20% prueba

### Fuente y Licencia
- **Licencia**: Uso acad√©mico/no comercial √∫nicamente (seg√∫n t√©rminos de Kaggle)
- **Restricciones**: Prohibido uso comercial seg√∫n los t√©rminos del concurso APTOS 2019
- **Uso permitido**: Exclusivamente para investigaci√≥n acad√©mica y educativa
- **Cumplimiento √©tico**: Este proyecto se adhiere estrictamente a los t√©rminos de uso del dataset

## üöÄ C√≥mo Ejecutar

### Requisitos Previos
- Python 3.8+
- GPU NVIDIA con CUDA (recomendado)
- Jupyter Notebook o Google Colab

### Configuraci√≥n del Entorno

#### Opci√≥n 1: Google Colab (Recomendado)
1. Abre los notebooks en Google Colab
2. **Activa GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí T4/A100
3. Los notebooks est√°n optimizados para Colab con montaje autom√°tico de Google Drive

#### Opci√≥n 2: Local con Jupyter
```bash
# Clonar el repositorio
git clone https://github.com/haroldeustaquio/Proyecto_EustaquioHarold_Clasificacion.git
cd Proyecto_EustaquioHarold_Clasificacion

# Instalar dependencias
pip install -r requirements.txt

# Iniciar Jupyter
jupyter notebook
```

### Estructura de Notebooks
- `00_preprocessing.ipynb`: Preprocesamiento completo de datos
- `01_training.ipynb`: Entrenamiento de los tres modelos
- `02_eval_inference.ipynb`: Evaluaci√≥n y an√°lisis de resultados

## üéØ C√≥mo Entrenar y Evaluar

### Paso 1: Preprocesamiento de Datos
```python
# Ejecutar notebook: 00_preprocessing.ipynb
# Incluye:
# - Reagrupaci√≥n de clases (5 ‚Üí 3 categor√≠as)
# - Conversi√≥n PNG ‚Üí JPG
# - Recorte centrado de retina
# - Realce de contraste CLAHE
# - Filtro bilateral para reducci√≥n de ruido
# - Divisi√≥n estratificada train/val/test
# - Balanceo de clases con data augmentation
```

### Paso 2: Entrenamiento de Modelos
```python
# Ejecutar notebook: 01_training.ipynb
# Arquitecturas implementadas:
# - ResNet50
# - EfficientNet-B3  
# - MobileNet-V3-Large

# Configuraci√≥n de entrenamiento:
# - Learning rates diferenciales (head: 1e-3, backbone: 1e-4)
# - Mixed Precision Training (AMP)
# - Label Smoothing (Œ±=0.05)
# - Early Stopping basado en F1-macro
# - ReduceLROnPlateau scheduler
```

### Paso 3: Evaluaci√≥n y An√°lisis
```python
# Ejecutar notebook: 02_eval_inference.ipynb
# Incluye:
# - M√©tricas comprensivas (Accuracy, F1, AUC, Kappa, MCC)
# - Matrices de confusi√≥n
# - Curvas de entrenamiento
# - Inferencias en im√°genes de prueba
# - Comparaci√≥n entre arquitecturas
```

## üìä Arquitecturas Implementadas

### üèóÔ∏è ResNet50
- **Caracter√≠sticas**: Conexiones residuales, 50 capas
- **Ventajas**: Baseline robusto, evita vanishing gradients
- **Uso**: Clasificaci√≥n de referencia

### ‚ö° EfficientNet-B3  
- **Caracter√≠sticas**: Compound scaling, squeeze-and-excitation
- **Ventajas**: Mejor eficiencia computacional, menos par√°metros
- **Uso**: Mejor balance precisi√≥n/eficiencia

### üì± MobileNet-V3-Large
- **Caracter√≠sticas**: Depthwise separable convolutions, hard-swish
- **Ventajas**: Optimizado para dispositivos m√≥viles
- **Uso**: Deployment en producci√≥n con recursos limitados

## üìà C√≥mo Generar M√©tricas y Visualizaciones

### M√©tricas Calculadas
El sistema calcula autom√°ticamente las siguientes m√©tricas:

**M√©tricas B√°sicas:**
- Accuracy y Balanced Accuracy
- F1-Score macro
- Precision y Recall macro

**M√©tricas Avanzadas:**
- ROC-AUC macro
- Average Precision (PR-AUC) macro
- Cohen's Kappa
- Matthews Correlation Coefficient (MCC)

**Visualizaciones:**
- Matrices de confusi√≥n
- Curvas de entrenamiento (loss, F1, accuracy, AUC)
- Ejemplos de inferencia con predicciones top-k

### Generar Tabla de Resultados
```python
# En 02_eval_inference.ipynb, al final:
# Se genera autom√°ticamente una tabla comparativa con todas las m√©tricas

# Ejemplo de tabla generada:
metrics_comparison = pd.concat([
    resnet_metrics_df, 
    mobilenet_metrics_df, 
    efficientnet_metrics_df
])
print(metrics_comparison)
```

### Generar Gr√°ficos de M√©tricas
```python
# Las funciones de visualizaci√≥n est√°n incluidas en 02_eval_inference.ipynb:

# Curvas de entrenamiento
plot_series(f1_scores, title="F1-Macro Evolution", ylabel="F1-Score")
plot_series(accuracy_scores, title="Accuracy Evolution", ylabel="Accuracy")

# Matrices de confusi√≥n
plot_confusion(cm, class_names, title="Confusion Matrix - Test Set")

# Comparaci√≥n entre modelos
plot_model_comparison(metrics_df)
```

## üîß Configuraciones T√©cnicas

### Optimizaciones Implementadas
- **CUDA**: Optimizaciones cudnn.benchmark y allow_tf32
- **Mixed Precision**: Automatic Mixed Precision (AMP) para acelerar entrenamiento
- **DataLoaders**: Optimizados con pin_memory, persistent_workers, prefetch_factor
- **Compilaci√≥n**: torch.compile para mayor eficiencia
- **Memory Format**: channels_last para mejor rendimiento en GPU

### Hiperpar√°metros Principales
```python
BATCH_SIZE = 32
EPOCHS = 30 (con early stopping)
LR_HEAD = 1e-3
LR_BACKBONE = 1e-4
WEIGHT_DECAY = 1e-4
DROPOUT = 0.2
LABEL_SMOOTHING = 0.05
```

## üìÅ Estructura del Proyecto

```
DL-PhawIA/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ original/           # Datos originales
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Datos procesados
‚îÇ   ‚îú‚îÄ‚îÄ structured/         # Datos organizados por clases
‚îÇ   ‚îî‚îÄ‚îÄ structured-balanced/ # Datos balanceados
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 00_preprocessing.ipynb    # Preprocesamiento
‚îÇ   ‚îú‚îÄ‚îÄ 01_training.ipynb         # Entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ 02_eval_inference.ipynb   # Evaluaci√≥n
‚îú‚îÄ‚îÄ models/                 # Checkpoints guardados
‚îú‚îÄ‚îÄ results/               # Resultados y visualizaciones
‚îî‚îÄ‚îÄ requirements.txt       # Dependencias
```

## üìã Resultados Principales

Los modelos entrenados alcanzan m√©tricas competitivas en la clasificaci√≥n de retinopat√≠a diab√©tica:

| Modelo | F1_macro_Val | F1_macro_Test | Balanced_Accuracy_Val | Balanced_Accuracy_Test | ROC_AUC_macro_Val | ROC_AUC_macro_Test |
|--------|--------------|---------------|----------------------|------------------------|-------------------|-------------------|
| ResNet-50 | 0.821 | 0.838 | 0.816 | 0.835 | 0.954 | 0.953 |
| MobileNetV3-Large | 0.851 | 0.853 | 0.852 | 0.855 | 0.949 | 0.954 |
| EfficientNet-B3 | 0.849 | 0.853 | 0.843 | 0.847 | 0.941 | 0.950 |

## üîç An√°lisis y Conclusiones

El proyecto proporciona:
1. **Pipeline completo**: Desde preprocesamiento hasta evaluaci√≥n
2. **Comparaci√≥n rigurosa**: Tres arquitecturas con m√©tricas comprehensivas
3. **Optimizaciones modernas**: Mixed precision, data augmentation, early stopping
4. **Visualizaciones detalladas**: Matrices de confusi√≥n, curvas de entrenamiento
5. **C√≥digo reproducible**: Semillas fijas y configuraci√≥n determin√≠stica

## üìû Contacto

Para consultas o colaboraciones, consultar notebooks o resultados en `results/`.

---

**Nota**: Proyecto exclusivamente para investigaci√≥n acad√©mica. No apto para uso cl√≠nico sin supervisi√≥n profesional. Este trabajo cumple con los t√©rminos de uso acad√©mico/no comercial del dataset APTOS 2019 Blindness Detection de Kaggle, respetando las restricciones √©ticas y legales establecidas para el uso responsable de datos m√©dicos.